{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8038,
     "status": "ok",
     "timestamp": 1573684044823,
     "user": {
      "displayName": "Brian Maddock",
      "photoUrl": "",
      "userId": "13704598861128573402"
     },
     "user_tz": 480
    },
    "id": "tglqHR2wUbN1",
    "outputId": "a713b66e-7c93-4c3a-f77f-b1b96e4e817a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from string import punctuation\n",
    "import re\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 300)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import time \n",
    "\n",
    "\n",
    "df = pd.read_csv('~/ML/NFL/finalSetSmall.csv')\n",
    "df1 = df.select_dtypes(exclude=['object'])\n",
    "df2 = df.select_dtypes(['object'])\n",
    "df1 = df1.replace([np.inf, -np.inf], np.nan)\n",
    "df1 = df1.replace(np.nan, 10)\n",
    "yTrain = df1['Yards']\n",
    "playId = df1['PlayId']\n",
    "xTrain = df1.drop(['GameId',  'PlayId', 'Yards'], axis=1)\n",
    "#xTrain = pd.get_dummies(xTrain)\n",
    "\n",
    "\n",
    "\n",
    "x1 = xTrain.iloc[:23000].to_numpy()\n",
    "y = yTrain.iloc[:23000].to_numpy()\n",
    "\n",
    "xTest1 = xTrain.iloc[23000:].to_numpy()\n",
    "yTest = yTrain.iloc[23000:].to_numpy()\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "pt = preprocessing.PowerTransformer()\n",
    "\n",
    "#xNorm = pt.fit_transform(x1)\n",
    "#xNormTest = pt.transform(xTest1)\n",
    "\n",
    "xScale = scaler.fit_transform(x1)\n",
    "xScaleTest = scaler.transform(xTest1)\n",
    "\n",
    "#poly = PolynomialFeatures(2)\n",
    "#xPoly = poly.fit_transform(xScale) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfDummies = pd.get_dummies(df2)\n",
    "# dummies = dfDummies.to_numpy()\n",
    "# sel = VarianceThreshold(threshold = 0.1)\n",
    "# dummies2 = sel.fit_transform(dummies)\n",
    "# dummies2.shape\n",
    "# dummiesTry = dummies2[:23000]\n",
    "# dummiesTest = dummies2[23000:]\n",
    "# xScale = np.concatenate((dummiesTry, xScale), axis=1)\n",
    "# xScaleTest = np.concatenate((dummiesTest, xScaleTest), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sel = VarianceThreshold(threshold = 1)\n",
    "# xScalePrime = sel.fit_transform(xScale)\n",
    "# xScaleTestPrime = sel.transform(xScaleTest)\n",
    "\n",
    "# poly = PolynomialFeatures(2)\n",
    "# xScalePoly = poly.fit_transform(xScalePrime)\n",
    "# xScaleTestPoly = poly.transform(xScaleTestPrime)\n",
    "\n",
    "# xScale = xScalePoly\n",
    "# xScaleTest = xScaleTestPoly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "\n",
    "from sklearn import linear_model\n",
    "reg1 = linear_model.Ridge(alpha=0.001, solver = 'svd')\n",
    "reg2 = linear_model.Ridge(alpha=0.001, solver = 'cholesky')\n",
    "reg3 = linear_model.Ridge(alpha=0.001, solver = 'lsqr')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf1 = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rf2 = RandomForestClassifier(n_estimators=300, random_state=0)\n",
    "rf3 = RandomForestClassifier(n_estimators=50, random_state=0)\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "svr = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "nnR = MLPRegressor(alpha=1e-6, hidden_layer_sizes=(1000,), random_state=1)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "nnC = MLPClassifier(alpha=1e-6, hidden_layer_sizes=(50,), random_state=1)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "KNN = KNeighborsRegressor(n_neighbors=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_func(mu, sigma, bins): \n",
    "    val = 1/(sigma*np.sqrt(2*np.pi))*np.exp(-1*(bins - mu)**2/(2*sigma**2))\n",
    "    return val\n",
    "                                            \n",
    "def gauss(pred):\n",
    "    predList = []\n",
    "    sumVal = 0\n",
    "    for i in range(-99, 100): \n",
    "        sumVal += gauss_func(pred, 3, i)\n",
    "        predList.append(sumVal)\n",
    "    return predList\n",
    "\n",
    "def y_cdf(yTest): \n",
    "    array = np.zeros((len(yTest), 199))\n",
    "    for j in range(len(yTest)): \n",
    "        for i in range(int(yTest[j])+99):\n",
    "            array[j][i] = 1\n",
    "    array = 1-array\n",
    "    \n",
    "    return array\n",
    "   \n",
    "def score(out, label): \n",
    "    score = np.sum(np.power(out-label,2))/(199)\n",
    "    return score\n",
    "\n",
    "def mse(yards, prediction):\n",
    "    mean = ((yards - prediction)*(yards - prediction)).sum()/len(yards)\n",
    "    return mean\n",
    "\n",
    "y_test_cdf = np.asarray(y_cdf(yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hq3A07lFUh09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384.2779870033264\n"
     ]
    }
   ],
   "source": [
    "beginTime = time.time()\n",
    "reg1.fit(xScale, y)\n",
    "rf1.fit(xScale, y)\n",
    "#svr.fit(xScale, y)\n",
    "nnR.fit(xScale, y)\n",
    "#reg3.fit(xScale, y)\n",
    "print(time.time() - beginTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beginTime = time.time()\n",
    "# nnR.fit(xScale, y)\n",
    "# print(time.time() - beginTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This SVR instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c8a8728102bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m regPreds = [reg1.predict(xScaleTest), rf1.predict(xScaleTest), svr.predict(xScaleTest), \n\u001b[0m\u001b[1;32m      2\u001b[0m            nnR.predict(xScale, y)]\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregPreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'support_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=np.float64, order=\"C\",\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This SVR instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "regPreds = [reg1.predict(xScaleTest), rf1.predict(xScaleTest), svr.predict(xScaleTest), \n",
    "           nnR.predict(xScale, y)]\n",
    "\n",
    "for j in range(len(regPreds)):\n",
    "    scores = []\n",
    "    for i in range(len(yTest)): \n",
    "        scores.append(score(y_test_cdf[i], gauss(regPreds[j][i])))\n",
    "    scores = np.asarray(scores)\n",
    "    print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(data_frame, estimators, params, filename, poly_fit):\n",
    "\n",
    "    print(\"here: 1\")\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "    logging.basicConfig(filename=filename, filemode='w', level=logging.INFO)\n",
    "    logger = logging.getLogger()\n",
    "    \n",
    "    minimal_error, best_estimator = None, None\n",
    "    \n",
    "    for estimator in estimators:\n",
    "        \n",
    "        try: \n",
    "            print(f\"Starting with estimator: {estimator.__name__}\")\n",
    "            logging.info(f\"Starting with estimator: {estimator.__name__}\")\n",
    "\n",
    "            for index, cur_params in enumerate(params[estimator.__name__]):\n",
    "                print(cur_params)\n",
    "                regressor = estimator(**cur_params)\n",
    "                print(\"here: 2\")\n",
    "\n",
    "                # To collect MSE over each split\n",
    "                errors = []\n",
    "\n",
    "                # to collect accuracies\n",
    "                accuracies = []\n",
    "                top_1_accs = []\n",
    "\n",
    "                #validation_data = data_frame\n",
    "                #validation_data = validation_data.sort_values(by='points_won', ascending=False)\n",
    "\n",
    "                # Get train data\n",
    "                train_x = XTrain\n",
    "                train_y = yTrain\n",
    "                print(\"here: 3\")\n",
    "                \n",
    "                # Validate over one season only\n",
    "                val_x = XVal\n",
    "                val_y = yVal\n",
    "                #val_y = val_y.reshape(val_y.shape[0], )\n",
    "                print(\"here: 4\")\n",
    "                \n",
    "\n",
    "                if poly_fit is not None:\n",
    "                    train_x = poly_fit.fit_transform(train_x)\n",
    "                    val_x = poly_fit.fit_transform(val_x)\n",
    "\n",
    "                \n",
    "                shuffle_x, shuffle_y = shuffle(train_x, train_y)\n",
    "                \n",
    "\n",
    "                regressor.fit(shuffle_x, shuffle_y)\n",
    "                predicted_y = regressor.predict(val_x)\n",
    "\n",
    "                sorted_indices = np.argsort(predicted_y)[::-1]\n",
    "                correct_indices = np.arange(len(val_y))\n",
    "\n",
    "                curr_error = mean_squared_error(val_y, predicted_y)\n",
    "                errors.append(curr_error)\n",
    "                mean_error = np.average(errors)\n",
    "            \n",
    "                logging.info(f\"Params: {cur_params}, MSE over all splits is: {mean_error:.4f}\")\n",
    "                print(\n",
    "                    f\"Params: {cur_params}, MSE over all splits is: {mean_error:.4f}\")\n",
    "\n",
    "                if minimal_error is None or mean_error < minimal_error:\n",
    "                    minimal_error = mean_error\n",
    "                    best_estimator = estimator(**cur_params)\n",
    "        except Exception:\n",
    "            print(f\"Exception: {estimator}\")\n",
    "            continue\n",
    "            \n",
    "    return best_estimator\n",
    "\n",
    "estimators = [Ridge]\n",
    "\n",
    "params = {Ridge.__name__: \n",
    "    [\n",
    "        {\n",
    "            'alpha': 1.0, 'solver':'svd'\n",
    "        },\n",
    "        {\n",
    "            'alpha': 10.0, 'solver':'svd'\n",
    "        },\n",
    "        {\n",
    "            'alpha': 30.0, 'solver':'svd'\n",
    "        },\n",
    "        {\n",
    "            'alpha': 50.0, 'solver':'svd'\n",
    "        },\n",
    "    ],\n",
    "         }\n",
    "\n",
    "best_estimator = pipeline(\n",
    "    data_frame=val_data,\n",
    "    estimators=estimators,\n",
    "    params=params,\n",
    "    filename=\"log_reg_poly_2.txt\",\n",
    "    # scaler=MinMaxScaler(),\n",
    "    poly_fit=PolynomialFeatures(degree=2, interaction_only=True),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Model Building.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
